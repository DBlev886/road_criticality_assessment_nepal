# -*- coding: utf-8 -*-
"""
Created on Sun May  8 12:04:30 2022

@author: Danny Baldig

Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope Process
venv\scripts\activate


# = comments on what code does
### = methodological comment (just for me)
##### = new sub-chapter
########## = new chapter
"""


#%%
########## INPUTS and IMPORTS
download_path ='C:/Users/Danny/Desktop/EMMA/IV/Data/' # enter path for (temporary) downloads
lc_path = "C:/Users/Danny/Desktop/EMMA/IV/Data/Land_cover/data/LandCover_NP_2019.tif" # path of land cover raster; trying to automate this later but download is behind log-in wall, so that requires an account for every user
study_area = (["Beni, Nepal", "Jaljala, Nepal"])    # Use OSM Nominatim in comma-seperated strings: https://nominatim.openstreetmap.org/ui/search.html
population_type = "" #("constrained": for official population counts or "UNadj_constrained" for UN adjusted population counts)


### get rid of unused packages -> linter doesn't work
from ctypes.wintypes import HDWP
import osmnx as ox
import networkx as nx
import geopandas as gpd
import rasterio as rio
import rasterstats
from rasterio.warp import calculate_default_transform, reproject, Resampling
from rasterio.plot import show_hist
import rioxarray as rxr
import pandas as pd
from shapely.ops import linemerge
import fiona
from pyproj import CRS
import numpy as np
from matplotlib import pyplot
import matplotlib.pyplot as plt
import matplotlib as mpl
from rasterstats import zonal_stats
from shapely import speedups
speedups.enabled
from shapely.ops import unary_union
from shapely.ops import substring
from shapely import wkt
%matplotlib inline
import pprint
from shapely.geometry import Point, Polygon, MultiPoint, MultiLineString, MultiPolygon, LineString, shape
from math import sqrt
import pycountry
from rasterio.mask import mask
import os
from wpgpDownload.utils.wpcsv import ISO_LIST
from wpgpDownload.utils.wpcsv import Product
from wpgpDownload.utils.convenience_functions import download_country_covariates as dl

#%%
pd.set_option('display.max_colwidth', None)

#%%
########## RETRIEVE AND PROCESS OSM-DATA
# fetch OSM street network data
### use custom_filter instead of network_type for specific road types or utility lines


network = ox.graph_from_place(study_area, 
                              network_type="drive", 
                              clean_periphery=True)

# project the data
network_proj = ox.project_graph(network)
nodes, edges = ox.graph_to_gdfs(network_proj, 
                                nodes=True, 
                                edges=True)

#edges = edges.drop(
#                ["lanes",
#                 "maxspeed",
#                 "access"], 
#                 axis=1)

# Cannot write file: ValueError: Invalid field type <class 'list'>
#for col in edges.columns:
#    if any(isinstance(val, list) for val in edges[col]):
#        print('Column: {0}, has a list in it'.format(col))
#        #edges['highway'] = edges['osmid'].apply(lambda x: ' '.join(x))
#        #print('Column: {0}, has a list in it'.format(col))
#edges.columns = edges.columns.to_flat_index()
#edges.columns = edges.columns.get_level_values(0)
#outfp = "C:/Users/Danny/Desktop/EMMA/IV/Data/edges.shp"
#edges.to_file(outfp)



#%%
#edges = edges.assign(ref=lambda edges: edges.loc[:,"ref"].str.extract(r"(.*) \\.+") )
#edges = edges.dropna()

# define boundaries to mask raster
### buffer distance crucial to connect roads on the outside and to allow connectivitiy between multiple administrative units
AOI = ox.geocode_to_gdf(study_area)
AOI = AOI.dissolve()
AOI = AOI.to_crs(CRS(nodes.crs))
AOI['geometry'] = AOI.geometry.buffer(2000)
AOI_file = download_path + "aoi.shp"
AOI.to_file(AOI_file)

#%%
'''
# plot data
fig, ax = plt.subplots(figsize=(12,8))
edges.plot(ax=ax, linewidth=0.75, color='gray')
nodes.plot(ax=ax, markersize=2, color='gray')
'''

#%%

hw = edges[edges['highway'].isin(['trunk', 'primary', 'tertiary'])]


#%%
### apply function only to certain highway types later

def cut(line, distance=1000):
# Cuts a line in two at a distance from its starting point
    if distance <= 0.0 or distance >= line.length:
        return [LineString(line)]
    coords = list(line.coords)
    for i, p in enumerate(coords):
        pd = line.project(Point(p))
        if pd == distance:
            return [
                    LineString(coords[:i+1]),
                    LineString(coords[i:])]
        if pd > distance:
            cp = line.interpolate(distance)
            return [
                    LineString(coords[:i] + [(cp.x, cp.y)]),
                    LineString([(cp.x, cp.y)] + coords[i:])]


hw['cut'] = hw['geometry'].apply(cut)


#%%
hw['cut1'] = hw.cut.astype('str').str.split(', L', expand = True)[0]

try:
    hw['cut2'] = hw.cut.astype('str').str.split(', L', expand = True)[1]
except KeyError:
    pass

hw.head(2)
#%%
########## ASSIGN STRATEGICAL IMPORTANCE SCORES
###### ASSIGN CENTRALITY SCORES
### normalize centrality values to summarize them with population later to create quantiles
CC = nx.closeness_centrality(nx.line_graph(network_proj))
edges['cc'] = pd.DataFrame.from_dict(CC, orient='index')
edges['norm_cc'] = (edges['cc']-edges['cc'].min())/(edges['cc'].max()-edges['cc'].min())

BC = nx.betweenness_centrality(nx.line_graph(network_proj))#, weight="length")
edges['bc'] = pd.DataFrame.from_dict(BC, orient='index')
edges['norm_bc'] = (edges['bc']-edges['bc'].min())/(edges['bc'].max()-edges['bc'].min())

edges['centrality_avg'] = (edges['norm_cc'] + edges['norm_cc']) / 2

'''
edges.plot('norm_cc', label='cc', cmap='RdYlBu_r', legend=True)
edges.plot('norm_bc', label='bc', cmap='RdYlBu_r', legend=True)
edges.plot('centrality_avg', label='avg', cmap='RdYlBu_r', legend=True)
'''

#%%

highways = ['trunk', 'primary', 'tertiary']
rslt_df = edges[edges['highway'].isin(highways)]

rslt_df.plot()

#print(edges[edges['length'] > 1000])
#print(rslt_df[rslt_df['length'] > 1000])

#%%

##### ADD POPULATION RASTER AND ASSIGN POPULATION SCORES
# identify ISO country code to automatically download population raster based on OSM-input
if not download_path.endswith("/"):
    download_path = download_path + "/"

study_area_str = " ".join(study_area)
for country in pycountry.countries:
    if country.name in study_area_str:
        iso_code = country.alpha_3

#%%

products = Product(iso_code)  # Where instead of NPL it could be any valid ISO code.
#  to list all the products for NPL
#for p in products:
#    if "2020" in p.dataset_name: 
#        print('%s/%s\t%s\t%s' % (p.idx, p.country_name,p.dataset_name,p.path))

prod_name_input = "ppp_2020" + population_type

#dl(ISO=iso_code, out_folder=download_path, prod_name=prod_name_input)


#%%
# open downloaded raster, reproject, and mask with AOI boundary
# ERROR even though file is not opened somewhere else: CPLE_AppDefinedError: Deleting C:/Users/Danny/Desktop/EMMA/IV/Data/Population/npl_ppp_2020_UNadj_clipped.tif failed: Permission denied
raster_crs = CRS(AOI.crs).to_epsg()
mask_coords = AOI['geometry']
file_name = iso_code + "_" + prod_name_input + ".tif"
file_name = file_name.lower()
pop_path = download_path + file_name
file_substr = ".tif"
pop_idx = pop_path.index(file_substr)
pop_proj_tif = pop_path[:pop_idx] + "_reproj" + pop_path[pop_idx:]
pop_proj_clip_tif = pop_proj_tif[:pop_idx] + "_clipped" + pop_proj_tif[pop_idx:]

#%%
with rio.open(pop_path, mode='r+') as pop:
    transform, width, height = calculate_default_transform(
        pop.crs, raster_crs, pop.width, pop.height, *pop.bounds)
    kwargs = pop.meta.copy()
    kwargs.update({
        'crs': raster_crs,
        'transform': transform,
        'width': width,
        'height': height
    })

    with rio.open(pop_proj_tif, 'w', **kwargs) as pop_proj:
        for i in range(1, pop.count + 1):
            reproject(
                source=rio.band(pop, i),
                destination=rio.band(pop_proj, i),
                resampling=Resampling.nearest)


#%%
with rio.open(pop_proj_tif) as pop_proj:
    pop_out_image, out_transform = rio.mask.mask(pop_proj, AOI.geometry, crop=True)
    pop_out_meta = pop_proj.meta

pop_out_meta.update({"driver": "GTiff",
                 "height": pop_out_image.shape[1],
                 "width": pop_out_image.shape[2],
                 "transform": out_transform})

with rio.open(pop_proj_clip_tif, "w", **pop_out_meta) as pop_dest:
    pop_dest.write(pop_out_image)

#pop_dest.close() # close the rasterio dataset


#%%
# read clipped population raster and assign values to numpy nd array
#pop_count =  rio.open(clipped)
pop_raster = rio.open(pop_proj_clip_tif)
pop_count_array = pop_raster.read(1)
affine = pop_raster.transform


#%%
###################### BUFFER EDGES
# buffer edges
buffered = edges.buffer(100, cap_style=2)
buffered = gpd.GeoDataFrame(geometry=gpd.GeoSeries(buffered))
#buffered = buffered.dropna(axis=0, how=\"any\", thresh=None, subset=None, inplace=False)
#buffered.plot()


#%%

# calculating zonal statistics
pop_means = rasterstats.zonal_stats(edges, pop_count_array, 
                                            affine = affine,
                                            nodata = np.nan,
                                            stats = ['mean'],
                                            geojson_out = True)

# extract average population data from list
pop_mean_list = []
i = 0

while i < len(pop_means):
    pop_mean_list.append(pop_means[i]['properties'])
    i = i + 1



#%%
# transfer information from list to DataFrame and assign scores based on quantiles ## get NaN values if not converting index
pop_mean = pd.DataFrame(pop_mean_list)
pop_mean = pop_mean.set_index(edges.index)
edges['pop_mean'] = pop_mean['mean']
edges['norm_pop'] = (edges['pop_mean']-edges['pop_mean'].min())/(edges['pop_mean'].max()-edges['pop_mean'].min())
edges['si_quantile'] = edges['centrality_avg'] + edges['norm_pop']


#%%%
# qcut: quantile-based discretization to assign scores from 1 to 5 to centrality values
edges['si_score'] = pd.qcut(edges['si_quantile'], q=5, labels=[1,2,3,4,5]).astype(str)

'''
edges.plot('norm_cc', label='centrality', cmap='RdYlBu_r', legend=True)
edges.plot('norm_pop', label='population', cmap='RdYlBu_r', legend=True)
edges.plot('si_score', label='strategic importance', cmap='RdYlBu_r', legend=True)
'''

#%%
# trying to automatize land cover download /// doesn't work yet
import requests
import bs4

site_url = 'http://rds.icimod.org/DatasetMasters/DownloadFile/19?metadataid=1972729'
userid = 'danny.baldig@student.uibk.ac.at'
password = 'icimodPW977'

file_url = 'http://rds.icimod.org/DatasetMasters/DownloadFile/19?metadataid=1972729'
o_file = 'nlcms_2019.zip'

# create session
s = requests.Session()
# GET request. This will generate cookie for you
s.get(site_url)
# login to site.
s.post(site_url, data={'_username': userid, '_password': password})
# Next thing will be to visit URL for file you would like to download.
r = s.get(file_url)

# Download file
with open(o_file, 'wb') as output:
    output.write(r.content)
print(f"requests:: File {o_file} downloaded successfully!")

# Close session once all work done
s.close()

#%%%

lc_idx = lc_path.index(file_substr)
lc_proj_tif = lc_path[:lc_idx] + "_reproj" + lc_path[lc_idx:]
lc_proj_clip_tif = lc_proj_tif[:lc_idx] + "_clipped" + lc_proj_tif[lc_idx:]

with rio.open(lc_path) as lc:
    transform, width, height = calculate_default_transform(
        lc.crs, raster_crs, lc.width, lc.height, *lc.bounds)
    kwargs = lc.meta.copy()
    kwargs.update({
        'crs': raster_crs,
        'transform': transform,
        'width': width,
        'height': height
    })

    with rio.open(lc_proj_tif, 'w', **kwargs) as lc_proj:
        for i in range(1, lc.count + 1):
            reproject(
                source=rio.band(lc, i),
                destination=rio.band(lc_proj, i),
                resampling=Resampling.nearest)

with rio.open(lc_proj_tif) as lc_proj:
    lc_out_image, out_transform = rio.mask.mask(lc_proj, mask_coords, crop=True)
    lc_out_meta = lc_proj.meta

lc_out_meta.update({"driver": "GTiff",
                 "height": lc_out_image.shape[1],
                 "width": lc_out_image.shape[2],
                 "transform": out_transform})

# output with wrong CRS again
with rio.open(lc_proj_clip_tif, "w", **lc_out_meta) as lc_dest:
    lc_dest.write(lc_out_image)
    lc_dest.close()


#%%
# dataframe is a multiindex which causes problems

test_example = LineString(([0, 0], [2, 1], [3, 2], [3.5, 1], [5, 2]))

#line = edges["geometry"]
n = 10
def points_on_line(line):
    # or to get the distances closest to the desired one:
    # n = round(line.length / desired_distance_delta)
    distances = np.linspace(0, line.length, n)
    # or alternatively without NumPy:
    # distances = (line.length * i / (n - 1) for i in range(n))
    points = [line.interpolate(distance) for distance in distances]
    multipoint = unary_union(points)  
    new_line = LineString(points)


new = points_on_line(test_example)

#%%

# unique requires lots of processing
#zs = zonal_stats(edges, lc_proj_clip_tif)
edges['land_cover_majority'] = zonal_stats(edges, lc_proj_clip_tif,
            stats="majority")

edges['land_cover_minority'] = zonal_stats(edges, lc_proj_clip_tif,
            stats="minority")


#test = edges['geometry'].apply(points_on_line)
#test = edges.apply(lambda x: points_on_line)

#%%

edges['land_cover_final'] = np.where(edges.land_cover_majority == edges.land_cover_minority, edges['land_cover_majority'], edges['land_cover_majority'].astype(str) + edges['land_cover_minority'].astype(str))

edges['land_cover_final'] = edges['land_cover_final'].replace(["minority: .0"],"")
edges['land_cover_final'] = edges['land_cover_final'].map(lambda x: x.lstrip('+-').rstrip('minority: .0'))

print(edges['land_cover_final'])


#%%
# Read points from shapefile
pts = nodes[['x', 'y', 'geometry']]
pts.index = range(len(pts))
coords = [(x,y) for x, y in zip(pts.x, pts.y)]

# Open the raster and store metadata
raster = rio.open(lc_proj_clip_tif)
band1 = raster.read(1)

# Sample the raster at every point location and store values in DataFrame
pts['Raster Value'] = [x[0] for x in raster.sample(coords)]


plt.imshow(band1)
plt.tight_layout()

uniq_vals = np.unique(band1)
print(sorted(uniq_vals))

counts, bins = np.histogram(band1, bins=8)
for i in range(len(bins)-1):
    print("bin lower bound:", bins[i])
    print("counts:", counts[i])

'''print(raster.mode)
print(raster.count)
print(raster.width)
print(raster.height)
print(raster.crs)
print(raster.bounds)'''

'''
##### Land cover download
https://rds.icimod.org/DatasetMasters/DownloadFile/19?metadataid=1972729
'''

#%%
'''
# retrieve buildings
tags = {'building': True}
buildings = ox.geometries_from_place(study_area, tags)
buildings = buildings.to_crs(CRS(nodes.crs))


fig, ax = plt.subplots(figsize=(12,8))
# Plot edges and nodes
edges.plot(ax=ax, linewidth=0.75, color='gray')
nodes.plot(ax=ax, markersize=2, color='gray')
# Add buildings
ax = buildings.plot(ax=ax, facecolor='red', alpha=0.7)
# Add basemap
ctx.add_basemap(ax, crs=buildings.crs, source=ctx.providers.CartoDB.Positron)


# convert building polygons to points in lat, lon format and convert to gdf
building_centroids = buildings.centroid
building_centroids = gpd.GeoDataFrame(geometry=gpd.GeoSeries(building_centroids))
building_centroids = building_centroids.to_crs(nodes.crs)

building_centroids['x'] = building_centroids.geometry.apply(lambda x: x.x)
building_centroids['y'] = building_centroids.geometry.apply(lambda x: x.y)

#bounds = list(buffered.bounds.values[1])
#sindex = building_centroids.sindex


def intersect_using_spatial_index(building_centroids, buffered):
    """
    Conduct spatial intersection using spatial index for candidates GeoDataFrame to make queries faster.
    Note, with this function, you can have multiple Polygons in the 'intersecting_gdf' and it will return all the points
    intersect with ANY of those geometries.
    """
    source_sindex = building_centroids.sindex
    possible_matches_index = []

    # 'itertuples()' function is a faster version of 'iterrows()'
    for other in buffered.itertuples():
        bounds = other.geometry.bounds
        c = list(source_sindex.intersection(bounds))
        possible_matches_index += c

    # Get unique candidates
    unique_candidate_matches = list(set(possible_matches_index))
    possible_matches = building_centroids.iloc[unique_candidate_matches]

    # Conduct the actual intersect
    result = possible_matches.loc[possible_matches.intersects(buffered.unary_union)]
    return result


# Count intersections by postal code area
buildings_cnt = gpd.sjoin(buffered, building_centroids).groupby('key').size().reset_index()

buildings_cnt = buildings_cnt.rename(columns={0: 'buildings_cnt'})
buffered['buildings'] = buffered.merge(buildings_cnt, on='key')



def apply_tariff_iterrows(building_centroids):
    energy_cost_list = []
    for index, row in building_centroids.iterrows():
        geometry = buffered['geometry'].iloc[1]
        sindex = building_centroids.sindex
        possible_matches_index = list(sindex.intersection(geometry.bounds))
        possible_matches = building_centroids.iloc[possible_matches_index]
        precise_matches = possible_matches[possible_matches.intersects(geometry)]
        energy_cost_list << precise matches

'''

#%%%
'''
###################### ELEVATION GRADES ### not sure if this is useful eventually
########## node elevations and edge grades
# add node elevations from a single raster file
raster_path = "ASTGTMV003_N28E083_dem.tif"
network_elev = ox.elevation.add_node_elevations_raster(network_proj, raster_path)
assert not np.isnan(np.array(network_elev.nodes(data="elevation"))[:, 1]).any()
# add edge grades and their absolute values
network_elev = ox.elevation.add_edge_grades(network_elev, add_absolute=True)
# plot nodes by elevation and get one color for each node, by elevation, then plot the network
nc = ox.plot.get_node_colors_by_attr(network_elev, "elevation", cmap="plasma")
fig, ax = ox.plot_graph(network_elev, node_color=nc, node_size=5, edge_color="#333333", bgcolor="k")
'''

#%%

for col in edges.columns:
    if any(isinstance(val, list) for val in edges[col]):
        print('Column: {0}, has a list in it'.format(col))
        #edges['highway'] = edges['osmid'].apply(lambda x: ' '.join(x))
        #print('Column: {0}, has a list in it'.format(col))


#%%







#%%
# QUESTIONS
# better to use df.loc[:,['col']] instead of df['col']?
#
#
#
#
#
#
#