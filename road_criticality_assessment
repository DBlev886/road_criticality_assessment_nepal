# -*- coding: utf-8 -*-
"""
Created on Sun May  8 12:04:30 2022

@author: Danny Baldig


# = comments on what code does
### = methodological comment (just for me)
##### = new sub-chapter
########## = new chapter
"""

#%%
########## INPUTS
download_path ='C:/Users/Danny/Desktop/EMMA/IV/Data/' # enter path for (temporary) downloads
study_area = (["Beni, Nepal", "Jaljala, Nepal"])    # Please use OSM Nominatim: https://nominatim.openstreetmap.org/ui/search.html
population_type = "constrained" #("constrained": for official population counts or "UNadj_constrained" for UN adjusted population counts)

########## IMPORTS
#%%
import osmnx as ox
import networkx as nx
import geopandas as gpd
import rasterio as rio
import rasterstats
import pandas as pd
from shapely.ops import linemerge
import fiona
from pyproj import CRS
import numpy as np
import matplotlib.pyplot as plt
from shapely import speedups
speedups.enabled
import pprint
from shapely.geometry import Point, Polygon, MultiPoint, MultiLineString, MultiPolygon, LineString, shape
from matplotlib import pyplot
from math import sqrt
import pycountry
from rasterio.mask import mask
from wpgpDownload.utils.wpcsv import ISO_LIST
from wpgpDownload.utils.wpcsv import Product
from wpgpDownload.utils.convenience_functions import download_country_covariates as dl

#%%
########## RETRIEVE AND PROCESS OSM-DATA
# fetch OSM street network data
### use custom_filter instead of network_type for specific road types or utility lines
network = ox.graph_from_place(study_area, network_type="drive", buffer_dist=500, clean_periphery=True)

#%%
# project the data
network_proj = network #ox.project_graph(network)
network_nodes, network_edges = ox.graph_to_gdfs(network_proj, nodes=True, edges=True)
#network_edges = network_edges.dropna()

#%%
# define boundaries to mask raster
### buffer distance crucial to connect roads on the outside and to allow connectivitiy between multiple administrative units
AOI = ox.geocode_to_gdf(study_area)
AOI = AOI.dissolve()
AOI = AOI.to_crs(CRS(network_nodes.crs))
AOI_file = download_path + "aoi.shp"
AOI.to_file(AOI_file)

#%%
'''
# plot data
fig, ax = plt.subplots(figsize=(12,8))
network_edges.plot(ax=ax, linewidth=0.75, color='gray')
network_nodes.plot(ax=ax, markersize=2, color='gray')
'''

#%%
network_edges['segment_length'] = network_edges.length
# cut edges in 1000m segments
# ERROR: ValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().
# ERROR: GeometryTypeError: Unknown geometry type: featurecollection
def cut(line, distance):
# Cuts a line in two at a distance from its starting point
    if (distance <= 0.0) or (distance >= line['segment_length']):
        return [LineString(line)]
    coords = list(line.coords)
    for i, p in enumerate(coords):
        pd = line.project(Point(p))
        if pd == distance:
            return [
                    LineString(coords[:i+1]),
                    LineString(coords[i:])]
        if pd > distance:
            cp = line.interpolate(distance)
            return [
                    LineString(coords[:i] + [(cp.x, cp.y)]),
                    LineString([(cp.x, cp.y)] + coords[i:])]

### not sure if dissolve is the smartet way here or if I should dissolve bygroup
#network_to_cut = network_edges.dissolve()
#network_to_cut = linemerge(network_to_cut.iloc[0])
new_network = cut(network_edges, 1000.0)

#%%
########## ASSIGN STRATEGICAL IMPORTANCE SCORES
###### ASSIGN CENTRALITY SCORES
### normalize centrality values to summarize them with population later to create quantiles
centrality = nx.closeness_centrality(nx.line_graph(network_proj))
network_edges['centrality'] = pd.DataFrame.from_dict(centrality, orient='index')
network_edges['normalized_centrality'] = (network_edges['centrality']-network_edges['centrality'].min())/(network_edges['centrality'].max()-network_edges['centrality'].min())

#%%
##### ADD POPULATION RASTER AND ASSIGN POPULATION SCORES
# identify ISO country code to automatically download population raster based on OSM-input
if not download_path.endswith("/"):
    download_path = download_path + "/"

study_area_str = " ".join(study_area)
for country in pycountry.countries:
    if country.name in study_area_str:
        iso_code = country.alpha_3

'''products = Product(iso_code)  # Where instead of NPL it could be any valid ISO code.
#  to list all the products for NPL
for p in products:
    if "2020" in p.dataset_name: 
        print('%s/%s\t%s\t%s' % (p.idx, p.country_name,p.dataset_name,p.path))'''

prod_name_input = "ppp_2020_" + population_type
dl(ISO=iso_code, out_folder=download_path, prod_name=prod_name_input)

#%%
# open downloaded raster and mask with AOI boundary
# ERROR even though file is not opened somewhere else: CPLE_AppDefinedError: Deleting C:/Users/Danny/Desktop/EMMA/IV/Data/Population/npl_ppp_2020_UNadj_clipped.tif failed: Permission denied
file_name = iso_code + "_" + prod_name_input + ".tif"
file_name = file_name.lower()
with rio.open(download_path + file_name, mode='r+') as src:
    src.crs = network_nodes.crs
    pyplot.imshow(src.read(1), cmap='pink')
    def getFeatures(gdf):
        """Function to parse features from GeoDataFrame in such a manner that rasterio wants them"""
        import json
        return [json.loads(gdf.to_json())['features'][0]['geometry']]
    coords = AOI['geometry']
    clipped_array, clipped_transform = mask(dataset=src, shapes=coords)

    out_meta = src.meta.copy()
    out_meta.update({"driver": "GTiff",
                    "height": clipped_array.shape[1],
                    "width": clipped_array.shape[2],
                    "transform": clipped_transform})
    out_tif = download_path + file_name + "_clipped.tif"
    with rio.open(out_tif, "w", **out_meta) as dest:
        dest.write(clipped_array) 
    clipped = rio.open(out_tif)
    fig, ax = plt.subplots(figsize=(8, 6))
    p1 = AOI.plot(color=None,facecolor='none',edgecolor='red',linewidth = 2,ax=ax)

#%%
# read clipped population raster and assign values to numpy nd array
#pop_count =  rio.open(clipped)
pop_count_array = clipped.read(1)
affine = clipped.transform
#%%
# calculating zonal statistics
pop_mean = rasterstats.zonal_stats(network_edges, pop_count_array, affine = affine,
                                            stats = ['mean'],
                                            geojson_out = True)

# extract average population data from list
pop_mean_list = []
i = 0

while i < len(pop_mean):
    pop_mean_list.append(pop_mean[i]['properties'])
    i = i + 1

# transfer information from list to DataFrame and assign scores based on quantiles ## get NaN values if not converting index
pop_mean = pd.DataFrame(pop_mean_list)
pop_mean = pop_mean.set_index(network_edges.index)
network_edges['pop_mean'] = pop_mean['mean']
network_edges['normalized_pop'] = (network_edges['pop_mean']-network_edges['pop_mean'].min())/(network_edges['pop_mean'].max()-network_edges['pop_mean'].min())
network_edges['strategic_importance_quantile'] = network_edges['normalized_centrality'] + network_edges['normalized_pop']

# qcut: quantile-based discretization to assign scores from 1 to 5 to centrality values
network_edges['strategic_importance_score'] = pd.qcut(network_edges['strategic_importance_quantile'], q=5, labels=[1,2,3,4,5]).astype(str)

network_edges.plot('normalized_centrality', label='centrality', cmap='RdYlBu_r', legend=True)
network_edges.plot('normalized_pop', label='population', cmap='RdYlBu_r', legend=True)
network_edges.plot('strategic_importance_score', label='strategic importance', cmap='RdYlBu_r', legend=True)

#network_edges = network_edges.reindex(columns=['strategic_importance'])
#network_edges.plot(column='strategic_importance')
#outfp = 'C:/Users/Danny/Beni/edges_strategic.shp'
#network_edges.to_file(outfp)


# retrieve buildings
tags = {'building': True}
buildings = ox.geometries_from_place(study_area, tags)
buildings = buildings.to_crs(CRS(network_nodes.crs))

'''
fig, ax = plt.subplots(figsize=(12,8))
# Plot edges and nodes
network_edges.plot(ax=ax, linewidth=0.75, color='gray')
network_nodes.plot(ax=ax, markersize=2, color='gray')
# Add buildings
ax = buildings.plot(ax=ax, facecolor='red', alpha=0.7)
# Add basemap
ctx.add_basemap(ax, crs=buildings.crs, source=ctx.providers.CartoDB.Positron)
'''

###################### BUFFER EDGES
# buffer edges
buffered = network_edges.buffer(100, cap_style=2)
buffered = gpd.GeoDataFrame(geometry=gpd.GeoSeries(buffered))
#buffered = buffered.dropna(axis=0, how=\"any\", thresh=None, subset=None, inplace=False)
#buffered.plot()


#ax = buffered.plot(color='red', edgecolor='black', alpha=0.5)
#ax = buildings.plot(ax=ax, color='yellow', markersize=1, alpha=0.5)

'''
# convert building polygons to points in lat, lon format and convert to gdf
building_centroids = buildings.centroid
building_centroids = gpd.GeoDataFrame(geometry=gpd.GeoSeries(building_centroids))
building_centroids = building_centroids.to_crs(network_nodes.crs)

building_centroids['x'] = building_centroids.geometry.apply(lambda x: x.x)
building_centroids['y'] = building_centroids.geometry.apply(lambda x: x.y)

#bounds = list(buffered.bounds.values[1])
#sindex = building_centroids.sindex


def intersect_using_spatial_index(building_centroids, buffered):
    """
    Conduct spatial intersection using spatial index for candidates GeoDataFrame to make queries faster.
    Note, with this function, you can have multiple Polygons in the 'intersecting_gdf' and it will return all the points
    intersect with ANY of those geometries.
    """
    source_sindex = building_centroids.sindex
    possible_matches_index = []

    # 'itertuples()' function is a faster version of 'iterrows()'
    for other in buffered.itertuples():
        bounds = other.geometry.bounds
        c = list(source_sindex.intersection(bounds))
        possible_matches_index += c

    # Get unique candidates
    unique_candidate_matches = list(set(possible_matches_index))
    possible_matches = building_centroids.iloc[unique_candidate_matches]

    # Conduct the actual intersect
    result = possible_matches.loc[possible_matches.intersects(buffered.unary_union)]
    return result


# Count intersections by postal code area
buildings_cnt = gpd.sjoin(buffered, building_centroids).groupby('key').size().reset_index()

buildings_cnt = buildings_cnt.rename(columns={0: 'buildings_cnt'})
buffered['buildings'] = buffered.merge(buildings_cnt, on='key')



def apply_tariff_iterrows(building_centroids):
    energy_cost_list = []
    for index, row in building_centroids.iterrows():
        geometry = buffered['geometry'].iloc[1]
        sindex = building_centroids.sindex
        possible_matches_index = list(sindex.intersection(geometry.bounds))
        possible_matches = building_centroids.iloc[possible_matches_index]
        precise_matches = possible_matches[possible_matches.intersects(geometry)]
        energy_cost_list << precise matches



###################### CENTRALITY INDICES
# node closeness centrality
node_centrality = nx.closeness_centrality(network_proj)
# plot it
df = pd.DataFrame(data=pd.Series(node_centrality).sort_values(), columns=['cc'])
df['colors'] = ox.plot.get_colors(n=len(df), cmap='inferno', start=0.2)
df = df.reindex(network_proj.nodes())
nc = df['colors'].tolist()
fig, ax = ox.plot_graph(network_proj, bgcolor='k', node_size=30, node_color=nc, node_edgecolor='none', node_zorder=2,
                        edge_color='#555555', edge_linewidth=1.5, edge_alpha=1)

# edge closeness centrality: convert graph to a line graph so edges become nodes and vice versa

# list of edge values for the orginal graph
#ev = [network_gdf['centrality'][edge + (0,)] for edge in network_proj.edges()]

# color scale converted to list of colors for graph edges
norm = colors.Normalize(vmin=min(ev)*0.8, vmax=max(ev))
cmap = cm.ScalarMappable(norm=norm, cmap=cm.inferno)
ec = [cmap.to_rgba(cl) for cl in ev]

# color the edges in the original graph with closeness centralities in the line graph
fig, ax = ox.plot_graph(network_proj, bgcolor='k', node_size=0, node_color='w', node_edgecolor='gray', node_zorder=2,
                        edge_color=ec, edge_linewidth=1.5, edge_alpha=1)


###################### ELEVATION GRADES ### not sure if this is useful eventually
########## node elevations and edge grades
# add node elevations from a single raster file
raster_path = "ASTGTMV003_N28E083_dem.tif"
network_elev = ox.elevation.add_node_elevations_raster(network_proj, raster_path)
assert not np.isnan(np.array(network_elev.nodes(data="elevation"))[:, 1]).any()
# add edge grades and their absolute values
network_elev = ox.elevation.add_edge_grades(network_elev, add_absolute=True)
# plot nodes by elevation and get one color for each node, by elevation, then plot the network
nc = ox.plot.get_node_colors_by_attr(network_elev, "elevation", cmap="plasma")
fig, ax = ox.plot_graph(network_elev, node_color=nc, node_size=5, edge_color="#333333", bgcolor="k")
'''
# %%
